{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c0479a2cb399>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Seaborn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "\n",
    "# Seaborn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file into pandas\n",
    "# 3 files are yelp_labelled.txt, amazon_cells_labelled.txt, imdb_labelled.txt\n",
    "txt_file = 'amazon_cells_labelled.txt';\n",
    "df = pd.read_table(txt_file, sep='\\t')\n",
    "df.columns = ['reviews','sentiment']\n",
    "df['len'] = [len(x) for x in df['reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               reviews  sentiment  len\n",
      "0                          Good case, Excellent value.          1   27\n",
      "1                               Great for the jawbone.          1   22\n",
      "3                                    The mic is great.          1   17\n",
      "6          If you are Razr owner...you must have this!          1   43\n",
      "9                      And the sound quality is great.          1   31\n",
      "10   He was very impressed when going from the orig...          1   83\n",
      "12                            Very good quality though          1   24\n",
      "14   Highly recommend for any one who has a blue to...          1   56\n",
      "16                                    So Far So Good!.          1   16\n",
      "17                                       Works great!.          1   13\n",
      "20   I bought this to use with my Kindle Fire and a...          1   65\n",
      "22   I have yet to run this new battery below two b...          1   89\n",
      "24                Great Pocket PC / phone combination.          1   36\n",
      "25   I've owned this phone for 7 months now and can...          1   92\n",
      "30   This product is ideal for people like me whose...          1   71\n",
      "33   Car charger as well as AC charger are included...          1  104\n",
      "35                           It has kept up very well.          1   25\n",
      "37      The case is great and works fine with the 680.          1   46\n",
      "39   It has a great camera thats 2MP, and the pics ...          1   92\n",
      "41                          Nice headset priced right.          1   26\n",
      "43                        Excellent bluetooth headset.          1   28\n",
      "44                      It has all the features I want          1   30\n",
      "47                          This case seems well made.          1   26\n",
      "50   good protection and does not make phone too bu...          1   50\n",
      "51   A usable keyboard actually turns a PDA into a ...          1  102\n",
      "52   This phone is pretty sturdy and I've never had...          1   74\n",
      "53                                  I love this thing!          1   18\n",
      "54   Everything about it is fine and reasonable for...          1   61\n",
      "56   I even dropped this phone into a stream and it...          1  101\n",
      "57   I have been very happy with the 510 and have h...          1  116\n",
      "..                                                 ...        ...  ...\n",
      "923                                        Works good.          1   11\n",
      "924  Motorola finally got the voice quality of a bl...          1   68\n",
      "926       but it is great, i would really recommend it          1   44\n",
      "933  You get extra minutes so that you can carry ou...          1   78\n",
      "936  The headset fulfills my requirements so I am h...          1   68\n",
      "937               Logitech Bluetooth Headset is a 10!.          1   36\n",
      "938  I like the fact that it rests lightly against ...          1   75\n",
      "939  A lot of websites have been rating this a very...          1   70\n",
      "940  I have tried these cables with my computer and...          1   78\n",
      "944  It is easy to turn on and off when you are in ...          1   99\n",
      "945  I have had mine for about a year and this Chri...          1   93\n",
      "946   Otherwise, easy to install and use, clear sound.          1   48\n",
      "947                                      nice leather.          1   13\n",
      "949                                It is a joy to use.          1   19\n",
      "951                          Very satisifed with that.          1   25\n",
      "953  This is the phone to get for 2005.... I just b...          1   86\n",
      "955  Just reading on the specs alone makes you say ...          1   50\n",
      "956                           Love it.. Great armband.          1   24\n",
      "957  I really like this product over the Motorola b...          1  102\n",
      "959  I exchanged the sony ericson z500a for this an...          1   84\n",
      "960  I was very impressed with the price of the cases.          1   49\n",
      "961                Also makes it easier to hold on to.          1   35\n",
      "962  I use this product in a motor control center w...          1  129\n",
      "963                                  It's pretty easy.          1   17\n",
      "966                          Beautiful styling though.          1   25\n",
      "970                                 Excellent product.          1   18\n",
      "974  It is the best charger I have seen on the mark...          1   53\n",
      "975                                  SWEETEST PHONE!!!          1   17\n",
      "976             :-)Oh, the charger seems to work fine.          1   38\n",
      "977  It fits so securely that the ear hook does not...          1  124\n",
      "\n",
      "[500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "pos = df[(df['sentiment'] == 1)]\n",
    "neg = df[(df['sentiment'] == 0)]\n",
    "print(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique(words):\n",
    "    uniq = set()\n",
    "    for sentence in words:\n",
    "        for word in sentence:\n",
    "            uniq.add(word)\n",
    "    return len(uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "decoding str is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-72d92d7e1a37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Remove problems with encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviews'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviews'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\study\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\pandas-0.23.4-py3.6-win32.egg\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   3192\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3194\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3196\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-72d92d7e1a37>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Remove problems with encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviews'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reviews'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: decoding str is not supported"
     ]
    }
   ],
   "source": [
    "#Remove problems with encoding\n",
    "df['reviews'] = df['reviews'].apply(lambda x: unicode(x, errors=\"ignore\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, have, to, jiggle, the, plug, to, get, it, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment  len\n",
       "0                     [good, case, excellent, value]          1   27\n",
       "1                         [great, for, the, jawbone]          1   22\n",
       "2  [tied, to, charger, for, conversations, lastin...          0   79\n",
       "3                              [the, mic, is, great]          1   17\n",
       "4  [i, have, to, jiggle, the, plug, to, get, it, ...          0   74"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tokenize without the punctuation\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "# make reviews lowercase\n",
    "df['reviews'] = df['reviews'].apply(lambda x: x.lower())\n",
    "# tokenize\n",
    "df['reviews'] = df['reviews'].apply(lambda x: tokenizer.tokenize(x))\n",
    "# visual check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1864"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check feature count\n",
    "count_unique(df['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               reviews  sentiment  len\n",
      "699  [also, the, phone, doesn, t, seem, to, accept,...          0  107\n",
      "700         [you, can, t, beat, the, price, on, these]          1   34\n",
      "701  [comes, with, a, strong, light, that, you, can...          1  114\n",
      "702                    [lightweight, and, works, well]          1   27\n",
      "703                                 [so, just, beware]          0   15\n",
      "704  [i, love, this, cable, it, allows, me, to, con...          1   73\n",
      "705  [so, anyone, near, you, will, hear, part, of, ...          0   55\n",
      "706  [this, is, cool, because, most, cases, are, ju...          1   96\n",
      "707  [i, bought, this, phone, as, a, replacement, f...          0   80\n",
      "708  [appears, to, actually, outperform, the, origi...          1   87\n",
      "709  [can, t, store, anything, but, phone, numbers,...          0   46\n",
      "710  [it, lasts, less, than, 3o, minutes, if, i, ac...          0  115\n",
      "711                                    [poor, quality]          0   13\n",
      "712                   [jabra, ear, gels, r, the, best]          1   29\n",
      "713                                   [not, worth, it]          0   13\n",
      "714  [the, phone, crashed, completely, and, now, i,...          0   63\n",
      "715  [it, quit, working, after, i, d, used, it, for...          1  136\n",
      "716  [unfortunately, it, will, not, recharge, my, i...          0  142\n",
      "717                         [it, was, a, great, phone]          1   21\n",
      "718  [if, you, simply, want, a, small, flip, phone,...          0   99\n",
      "719  [good, value, works, fine, power, via, usb, ca...          1   60\n",
      "720  [my, phone, doesn, t, slide, around, my, car, ...          1  101\n",
      "721  [this, is, simply, the, best, bluetooth, heads...          1   60\n",
      "722  [think, it, over, when, you, plan, to, own, th...          0   84\n",
      "723  [in, the, span, of, an, hour, i, had, two, peo...          1   87\n",
      "724  [i, have, always, used, corded, headsets, and,...          1   85\n",
      "725  [this, case, has, passed, the, one, year, mark...          1   95\n",
      "726  [other, than, that, the, leather, is, nice, an...          1  111\n",
      "727  [it, has, everything, i, need, and, i, couldn,...          1   53\n",
      "728  [after, receiving, and, using, the, product, f...          0   63\n",
      "..                                                 ...        ...  ...\n",
      "969  [i, plugged, it, in, only, to, find, out, not,...          0   57\n",
      "970                               [excellent, product]          1   18\n",
      "971                    [earbud, piece, breaks, easily]          0   27\n",
      "972                                   [lousy, product]          0   14\n",
      "973  [this, phone, tries, very, hard, to, do, every...          0   89\n",
      "974  [it, is, the, best, charger, i, have, seen, on...          1   53\n",
      "975                                  [sweetest, phone]          1   17\n",
      "976          [oh, the, charger, seems, to, work, fine]          1   38\n",
      "977  [it, fits, so, securely, that, the, ear, hook,...          1  124\n",
      "978                              [not, enough, volume]          0   18\n",
      "979              [echo, problem, very, unsatisfactory]          0   35\n",
      "980  [you, could, only, take, 2, videos, at, a, tim...          0   69\n",
      "981                       [don, t, waste, your, money]          0   23\n",
      "982  [i, am, going, to, have, to, be, the, first, t...          0   69\n",
      "983  [adapter, does, not, provide, enough, charging...          0   49\n",
      "984  [there, was, so, much, hype, over, this, phone...          0   82\n",
      "985  [you, also, cannot, take, pictures, with, it, ...          0   79\n",
      "986                        [phone, falls, out, easily]          0   23\n",
      "987  [it, didn, t, work, people, can, not, hear, me...          0   51\n",
      "988  [the, text, messaging, feature, is, really, tr...          0   51\n",
      "989  [i, m, really, disappointed, all, i, have, now...          0   70\n",
      "990                            [painful, on, the, ear]          0   19\n",
      "991            [lasted, one, day, and, then, blew, up]          0   32\n",
      "992                                     [disappointed]          0   13\n",
      "993                          [kind, of, flops, around]          0   21\n",
      "994  [the, screen, does, get, smudged, easily, beca...          0   72\n",
      "995  [what, a, piece, of, junk, i, lose, more, call...          0   55\n",
      "996                  [item, does, not, match, picture]          0   28\n",
      "997  [the, only, thing, that, disappoint, me, is, t...          0   63\n",
      "998  [you, can, not, answer, calls, with, the, unit...          0   58\n",
      "\n",
      "[300 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "train= df[:int(df.shape[0]*0.7)]\n",
    "test = df[int(df.shape[0]*0.7):]\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "logreg = SklearnClassifier(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POS Tagging/Removal\n",
    "# POS tag\n",
    "df['posr']= df['reviews'].apply(lambda x: nltk.pos_tag(x))\n",
    "# Leave the non POS removal ones alone\n",
    "df['nposr'] = df['reviews']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>len</th>\n",
       "      <th>posr</th>\n",
       "      <th>nposr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>[tied, charger, conversations, lasting, more, ...</td>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>[mic, is, great]</td>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, have, to, jiggle, the, plug, to, get, it, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>[i, jiggle, plug, get, line, up, right, get, d...</td>\n",
       "      <td>[i, have, to, jiggle, the, plug, to, get, it, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment  len  \\\n",
       "0                     [good, case, excellent, value]          1   27   \n",
       "1                         [great, for, the, jawbone]          1   22   \n",
       "2  [tied, to, charger, for, conversations, lastin...          0   79   \n",
       "3                              [the, mic, is, great]          1   17   \n",
       "4  [i, have, to, jiggle, the, plug, to, get, it, ...          0   74   \n",
       "\n",
       "                                                posr  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                                   [great, jawbone]   \n",
       "2  [tied, charger, conversations, lasting, more, ...   \n",
       "3                                   [mic, is, great]   \n",
       "4  [i, jiggle, plug, get, line, up, right, get, d...   \n",
       "\n",
       "                                               nposr  \n",
       "0                     [good, case, excellent, value]  \n",
       "1                         [great, for, the, jawbone]  \n",
       "2  [tied, to, charger, for, conversations, lastin...  \n",
       "3                              [the, mic, is, great]  \n",
       "4  [i, have, to, jiggle, the, plug, to, get, it, ...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collection of adjectives, nouns, adverbs and verbs to keep\n",
    "pos_keep = [\"JJ\",\"JJR\",\"JJS\",\"NN\",\"NNP\",\"NNS\",\"RB\",\"RBR\",\"VB\",\"VBD\",\"VBG\",\"VBN\",\"VBZ\"]\n",
    "\n",
    "\n",
    "def remove_pos(full):\n",
    "    redc =[]\n",
    "    for pair in full:\n",
    "        if pair[1] in pos_keep:\n",
    "            redc.append(pair[0])\n",
    "    return redc\n",
    "# Remove the words that are not in pos_keep\n",
    "df['posr']= df['posr'].apply(lambda x: remove_pos(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1691\n"
     ]
    }
   ],
   "source": [
    "print(count_unique(df['posr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>len</th>\n",
       "      <th>posr</th>\n",
       "      <th>nposr</th>\n",
       "      <th>posr_stpd</th>\n",
       "      <th>nposr_stpd</th>\n",
       "      <th>posr_nstpd</th>\n",
       "      <th>nposr_nstpd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>[tied, charger, conversations, lasting, more, ...</td>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "      <td>[tied, charger, conversations, lasting, minute...</td>\n",
       "      <td>[tied, charger, conversations, lasting, 45, mi...</td>\n",
       "      <td>[tied, charger, conversations, lasting, more, ...</td>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>[mic, is, great]</td>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "      <td>[mic, great]</td>\n",
       "      <td>[mic, great]</td>\n",
       "      <td>[mic, is, great]</td>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, have, to, jiggle, the, plug, to, get, it, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>[i, jiggle, plug, get, line, up, right, get, d...</td>\n",
       "      <td>[i, have, to, jiggle, the, plug, to, get, it, ...</td>\n",
       "      <td>[jiggle, plug, get, line, right, get, decent, ...</td>\n",
       "      <td>[jiggle, plug, get, line, right, get, decent, ...</td>\n",
       "      <td>[i, jiggle, plug, get, line, up, right, get, d...</td>\n",
       "      <td>[i, have, to, jiggle, the, plug, to, get, it, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment  len  \\\n",
       "0                     [good, case, excellent, value]          1   27   \n",
       "1                         [great, for, the, jawbone]          1   22   \n",
       "2  [tied, to, charger, for, conversations, lastin...          0   79   \n",
       "3                              [the, mic, is, great]          1   17   \n",
       "4  [i, have, to, jiggle, the, plug, to, get, it, ...          0   74   \n",
       "\n",
       "                                                posr  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                                   [great, jawbone]   \n",
       "2  [tied, charger, conversations, lasting, more, ...   \n",
       "3                                   [mic, is, great]   \n",
       "4  [i, jiggle, plug, get, line, up, right, get, d...   \n",
       "\n",
       "                                               nposr  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                         [great, for, the, jawbone]   \n",
       "2  [tied, to, charger, for, conversations, lastin...   \n",
       "3                              [the, mic, is, great]   \n",
       "4  [i, have, to, jiggle, the, plug, to, get, it, ...   \n",
       "\n",
       "                                           posr_stpd  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                                   [great, jawbone]   \n",
       "2  [tied, charger, conversations, lasting, minute...   \n",
       "3                                       [mic, great]   \n",
       "4  [jiggle, plug, get, line, right, get, decent, ...   \n",
       "\n",
       "                                          nposr_stpd  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                                   [great, jawbone]   \n",
       "2  [tied, charger, conversations, lasting, 45, mi...   \n",
       "3                                       [mic, great]   \n",
       "4  [jiggle, plug, get, line, right, get, decent, ...   \n",
       "\n",
       "                                          posr_nstpd  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                                   [great, jawbone]   \n",
       "2  [tied, charger, conversations, lasting, more, ...   \n",
       "3                                   [mic, is, great]   \n",
       "4  [i, jiggle, plug, get, line, up, right, get, d...   \n",
       "\n",
       "                                         nposr_nstpd  \n",
       "0                     [good, case, excellent, value]  \n",
       "1                         [great, for, the, jawbone]  \n",
       "2  [tied, to, charger, for, conversations, lastin...  \n",
       "3                              [the, mic, is, great]  \n",
       "4  [i, have, to, jiggle, the, plug, to, get, it, ...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove stopwords\n",
    "# Import the list of stopwords from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Remove the stopwords and store in \"No Stops\" column\n",
    "stop = set(stopwords.words('english'))\n",
    "# Ensure \"not\" is kept\n",
    "stop.remove(\"not\")\n",
    "df['posr_stpd'] = df['posr'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['nposr_stpd'] = df['nposr'].apply(lambda x: [item for item in x if item not in stop])\n",
    "df['posr_nstpd'] = df['posr']\n",
    "df['nposr_nstpd'] = df['nposr']\n",
    "# visual check\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1636"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check feature count\n",
    "count_unique(df['posr_stpd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>len</th>\n",
       "      <th>posr</th>\n",
       "      <th>nposr</th>\n",
       "      <th>posr_stpd</th>\n",
       "      <th>nposr_stpd</th>\n",
       "      <th>posr_nstpd</th>\n",
       "      <th>nposr_nstpd</th>\n",
       "      <th>nposr_nstpd_nstem</th>\n",
       "      <th>posr_nstpd_nstem</th>\n",
       "      <th>nposr_stpd_nstem</th>\n",
       "      <th>posr_stpd_nstem</th>\n",
       "      <th>nposr_nstpd_port</th>\n",
       "      <th>posr_nstpd_port</th>\n",
       "      <th>nposr_stpd_port</th>\n",
       "      <th>posr_stpd_port</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excellent, value]</td>\n",
       "      <td>[good, case, excel, valu]</td>\n",
       "      <td>[good, case, excel, valu]</td>\n",
       "      <td>[good, case, excel, valu]</td>\n",
       "      <td>[good, case, excel, valu]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "      <td>[great, for, the, jawbone]</td>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>[great, jawbone]</td>\n",
       "      <td>[great, for, the, jawbon]</td>\n",
       "      <td>[great, jawbon]</td>\n",
       "      <td>[great, jawbon]</td>\n",
       "      <td>[great, jawbon]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>[tied, charger, conversations, lasting, more, ...</td>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "      <td>[tied, charger, conversations, lasting, minute...</td>\n",
       "      <td>[tied, charger, conversations, lasting, 45, mi...</td>\n",
       "      <td>[tied, charger, conversations, lasting, more, ...</td>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "      <td>[tied, to, charger, for, conversations, lastin...</td>\n",
       "      <td>[tied, charger, conversations, lasting, more, ...</td>\n",
       "      <td>[tied, charger, conversations, lasting, 45, mi...</td>\n",
       "      <td>[tied, charger, conversations, lasting, minute...</td>\n",
       "      <td>[tie, to, charger, for, convers, last, more, t...</td>\n",
       "      <td>[tie, charger, convers, last, more, minut, maj...</td>\n",
       "      <td>[tie, charger, convers, last, 45, minut, major...</td>\n",
       "      <td>[tie, charger, convers, last, minut, major, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>[mic, is, great]</td>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "      <td>[mic, great]</td>\n",
       "      <td>[mic, great]</td>\n",
       "      <td>[mic, is, great]</td>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "      <td>[mic, is, great]</td>\n",
       "      <td>[mic, great]</td>\n",
       "      <td>[mic, great]</td>\n",
       "      <td>[the, mic, is, great]</td>\n",
       "      <td>[mic, is, great]</td>\n",
       "      <td>[mic, great]</td>\n",
       "      <td>[mic, great]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i, have, to, jiggle, the, plug, to, get, it, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>[i, jiggle, plug, get, line, up, right, get, d...</td>\n",
       "      <td>[i, have, to, jiggle, the, plug, to, get, it, ...</td>\n",
       "      <td>[jiggle, plug, get, line, right, get, decent, ...</td>\n",
       "      <td>[jiggle, plug, get, line, right, get, decent, ...</td>\n",
       "      <td>[i, jiggle, plug, get, line, up, right, get, d...</td>\n",
       "      <td>[i, have, to, jiggle, the, plug, to, get, it, ...</td>\n",
       "      <td>[i, have, to, jiggle, the, plug, to, get, it, ...</td>\n",
       "      <td>[i, jiggle, plug, get, line, up, right, get, d...</td>\n",
       "      <td>[jiggle, plug, get, line, right, get, decent, ...</td>\n",
       "      <td>[jiggle, plug, get, line, right, get, decent, ...</td>\n",
       "      <td>[i, have, to, jiggl, the, plug, to, get, it, t...</td>\n",
       "      <td>[i, jiggl, plug, get, line, up, right, get, de...</td>\n",
       "      <td>[jiggl, plug, get, line, right, get, decent, v...</td>\n",
       "      <td>[jiggl, plug, get, line, right, get, decent, v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  sentiment  len  \\\n",
       "0                     [good, case, excellent, value]          1   27   \n",
       "1                         [great, for, the, jawbone]          1   22   \n",
       "2  [tied, to, charger, for, conversations, lastin...          0   79   \n",
       "3                              [the, mic, is, great]          1   17   \n",
       "4  [i, have, to, jiggle, the, plug, to, get, it, ...          0   74   \n",
       "\n",
       "                                                posr  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                                   [great, jawbone]   \n",
       "2  [tied, charger, conversations, lasting, more, ...   \n",
       "3                                   [mic, is, great]   \n",
       "4  [i, jiggle, plug, get, line, up, right, get, d...   \n",
       "\n",
       "                                               nposr  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                         [great, for, the, jawbone]   \n",
       "2  [tied, to, charger, for, conversations, lastin...   \n",
       "3                              [the, mic, is, great]   \n",
       "4  [i, have, to, jiggle, the, plug, to, get, it, ...   \n",
       "\n",
       "                                           posr_stpd  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                                   [great, jawbone]   \n",
       "2  [tied, charger, conversations, lasting, minute...   \n",
       "3                                       [mic, great]   \n",
       "4  [jiggle, plug, get, line, right, get, decent, ...   \n",
       "\n",
       "                                          nposr_stpd  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                                   [great, jawbone]   \n",
       "2  [tied, charger, conversations, lasting, 45, mi...   \n",
       "3                                       [mic, great]   \n",
       "4  [jiggle, plug, get, line, right, get, decent, ...   \n",
       "\n",
       "                                          posr_nstpd  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                                   [great, jawbone]   \n",
       "2  [tied, charger, conversations, lasting, more, ...   \n",
       "3                                   [mic, is, great]   \n",
       "4  [i, jiggle, plug, get, line, up, right, get, d...   \n",
       "\n",
       "                                         nposr_nstpd  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                         [great, for, the, jawbone]   \n",
       "2  [tied, to, charger, for, conversations, lastin...   \n",
       "3                              [the, mic, is, great]   \n",
       "4  [i, have, to, jiggle, the, plug, to, get, it, ...   \n",
       "\n",
       "                                   nposr_nstpd_nstem  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                         [great, for, the, jawbone]   \n",
       "2  [tied, to, charger, for, conversations, lastin...   \n",
       "3                              [the, mic, is, great]   \n",
       "4  [i, have, to, jiggle, the, plug, to, get, it, ...   \n",
       "\n",
       "                                    posr_nstpd_nstem  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                                   [great, jawbone]   \n",
       "2  [tied, charger, conversations, lasting, more, ...   \n",
       "3                                   [mic, is, great]   \n",
       "4  [i, jiggle, plug, get, line, up, right, get, d...   \n",
       "\n",
       "                                    nposr_stpd_nstem  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                                   [great, jawbone]   \n",
       "2  [tied, charger, conversations, lasting, 45, mi...   \n",
       "3                                       [mic, great]   \n",
       "4  [jiggle, plug, get, line, right, get, decent, ...   \n",
       "\n",
       "                                     posr_stpd_nstem  \\\n",
       "0                     [good, case, excellent, value]   \n",
       "1                                   [great, jawbone]   \n",
       "2  [tied, charger, conversations, lasting, minute...   \n",
       "3                                       [mic, great]   \n",
       "4  [jiggle, plug, get, line, right, get, decent, ...   \n",
       "\n",
       "                                    nposr_nstpd_port  \\\n",
       "0                          [good, case, excel, valu]   \n",
       "1                          [great, for, the, jawbon]   \n",
       "2  [tie, to, charger, for, convers, last, more, t...   \n",
       "3                              [the, mic, is, great]   \n",
       "4  [i, have, to, jiggl, the, plug, to, get, it, t...   \n",
       "\n",
       "                                     posr_nstpd_port  \\\n",
       "0                          [good, case, excel, valu]   \n",
       "1                                    [great, jawbon]   \n",
       "2  [tie, charger, convers, last, more, minut, maj...   \n",
       "3                                   [mic, is, great]   \n",
       "4  [i, jiggl, plug, get, line, up, right, get, de...   \n",
       "\n",
       "                                     nposr_stpd_port  \\\n",
       "0                          [good, case, excel, valu]   \n",
       "1                                    [great, jawbon]   \n",
       "2  [tie, charger, convers, last, 45, minut, major...   \n",
       "3                                       [mic, great]   \n",
       "4  [jiggl, plug, get, line, right, get, decent, v...   \n",
       "\n",
       "                                      posr_stpd_port  \n",
       "0                          [good, case, excel, valu]  \n",
       "1                                    [great, jawbon]  \n",
       "2  [tie, charger, convers, last, minut, major, pr...  \n",
       "3                                       [mic, great]  \n",
       "4  [jiggl, plug, get, line, right, get, decent, v...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming\n",
    "ps = nltk.PorterStemmer()\n",
    "ss = nltk.SnowballStemmer('english')\n",
    "ls = nltk.LancasterStemmer()\n",
    "\n",
    "# No Stemming\n",
    "df['nposr_nstpd_nstem'] = df['nposr_nstpd']\n",
    "df['posr_nstpd_nstem'] = df['posr_nstpd']\n",
    "df['nposr_stpd_nstem'] = df['nposr_stpd']\n",
    "df['posr_stpd_nstem'] = df['posr_stpd']\n",
    "# Porter\n",
    "df['nposr_nstpd_port'] = df['nposr_nstpd'].apply(lambda x: [ps.stem(y) for y in x])\n",
    "df['posr_nstpd_port'] = df['posr_nstpd'].apply(lambda x: [ps.stem(y) for y in x])\n",
    "df['nposr_stpd_port'] = df['nposr_stpd'].apply(lambda x: [ps.stem(y) for y in x])\n",
    "df['posr_stpd_port'] = df['posr_stpd'].apply(lambda x: [ps.stem(y) for y in x])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test and evaluate with NB and LR\n",
    "#Function to Convert the Data into a Feature Set\n",
    "## Transform data into list of ([tokens],sentiment label)\n",
    "def createTrainingDataNLTK(sentences,labels):\n",
    "    rdata = np.vstack([sentences,labels])\n",
    "    rdata = np.transpose(rdata)\n",
    "    data = list();\n",
    "    for i in range(0,len(rdata)):\n",
    "        tokens = rdata[i][0].split(\" \")\n",
    "        d_tuple = (tokens, rdata[i][1]);\n",
    "        data.append(d_tuple)\n",
    "    return data;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE TRAINING DATA\n",
    "# create a list of all possible feature reduction permutations in the order of stopword removal_pos_stem\n",
    "featurereductions = ['nposr_nstpd_nstem', 'posr_nstpd_nstem', \n",
    "                     'nposr_stpd_nstem', 'posr_stpd_nstem', \n",
    "                     'nposr_nstpd_port', 'nposr_nstpd_snow', 'nposr_nstpd_lanc', 'nposr_stpd_port', 'nposr_stpd_snow', 'nposr_stpd_lanc',\n",
    "                     'posr_nstpd_port', 'posr_nstpd_snow', 'posr_nstpd_lanc', 'posr_stpd_port', 'posr_stpd_snow', 'posr_stpd_lanc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the words into sentence to use current implementation of createTrainingData\n",
    "def create_nltk_train_data (feature_reduction):\n",
    "    df['sentences'] = df[feature_reduction].apply(lambda x: \" \".join(x).encode('UTF-8'))\n",
    "    x_label = \"sentences\"\n",
    "    y_label = \"sentiment\"\n",
    "    nltk_train_data = createTrainingDataNLTK(df[x_label],df[y_label])\n",
    "    return nltk_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the accuracy of the test data for Naive Bayes\n",
    "# when predicted against fitted training data\n",
    "def train1(training_set,test_set):\n",
    "    \n",
    "    sentim_analyzer = SentimentAnalyzer()\n",
    "    all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_set])\n",
    "    unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
    "    sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)\n",
    "    \n",
    "    training_set = sentim_analyzer.apply_features(training_set)\n",
    "    test_set = sentim_analyzer.apply_features(test_set)\n",
    "                                              \n",
    "    trainer = NaiveBayesClassifier.train\n",
    "    classifier = sentim_analyzer.train(trainer, training_set)\n",
    "    results = sentim_analyzer.evaluate(test_set).items()                             \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the accuracy of the test data for Logistic Regression\n",
    "# when predicted against fitted training data\n",
    "def train2(training_set,test_set):\n",
    "    \n",
    "    sentim_analyzer = SentimentAnalyzer()\n",
    "    all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_set])\n",
    "    unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
    "    sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)\n",
    "    \n",
    "    training_set = sentim_analyzer.apply_features(training_set)\n",
    "    test_set = sentim_analyzer.apply_features(test_set)\n",
    "                                              \n",
    "    trainer = logreg.train\n",
    "    classifier = sentim_analyzer.train(trainer, training_set)\n",
    "    results = sentim_analyzer.evaluate(test_set).items()                             \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A custom parser function to interpret results of training function\n",
    "def nltk_parser(results,summer):\n",
    "    for key,value in sorted(results):\n",
    "        #print('{0}: {1}'.format(key, value))\n",
    "        if key == \"Accuracy\": summer += value;\n",
    "    \n",
    "    return summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-fold cross validation designed to be agnostic to training data and training function\n",
    "def k_fold_validation(k,data,train_func,parser):\n",
    "    \n",
    "    b_length = len(data)/k; # the testing bucket length\n",
    "    sum_acc = 0; # Use this for average accuracy\n",
    "    print (k, \"- fold cross validation\")\n",
    "    print (\"-----------------------------\")\n",
    "    for i in range(0,k):       \n",
    "        s_i = i*b_length; # testing interval start index\n",
    "        f_i = s_i + b_length; # testing interval end index\n",
    "        test_data = data[s_i:f_i]\n",
    "        train_data = data[0:s_i]+data[f_i:len(data)];\n",
    "        metrics = train_func(train_data,test_data);\n",
    "        sum_acc = parser(metrics,sum_acc);\n",
    "\n",
    "    print ('\\nAverage Accuracy:', sum_acc / k);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-fold cross validation designed to be agnostic to training data and training function\n",
    "# Returns average accuracy\n",
    "def k_fold_validation_simple(k,data,train_func,parser):\n",
    "    b_length = len(data)/k; # the testing bucket length\n",
    "    sum_acc = 0; # Use this for average accuracy\n",
    "    for i in range(0,k):       \n",
    "        s_i = i*b_length; # testing interval start index\n",
    "        f_i = s_i + b_length; # testing interval end index\n",
    "        test_data = data[s_i:f_i]\n",
    "        train_data = data[0:s_i]+data[f_i:len(data)];\n",
    "        metrics = train_func(train_data,test_data);\n",
    "        sum_acc = parser(metrics,sum_acc);\n",
    "    return sum_acc / k;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-6bc38aafedf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdict_metrics_nb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturereductions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnltk_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_nltk_train_data\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeaturereductions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeaturereductions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0maccuracies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fold_validation_simple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnltk_train_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnltk_parser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-69-4eb1822ba684>\u001b[0m in \u001b[0;36mcreate_nltk_train_data\u001b[1;34m(feature_reduction)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sentences\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sentiment\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnltk_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateTrainingDataNLTK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnltk_train_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-15fa2bf3a542>\u001b[0m in \u001b[0;36mcreateTrainingDataNLTK\u001b[1;34m(sentences, labels)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0md_tuple\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_tuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "#Naive Bayes testing\n",
    "K = 5; # Constant for K-fold cross validation\n",
    "accuracies =[]\n",
    "dict_metrics_nb = {}\n",
    "for i in range(0, len(featurereductions)):\n",
    "    nltk_train_data = create_nltk_train_data (featurereductions[i])\n",
    "    print (featurereductions[i])\n",
    "    accuracies.append(k_fold_validation_simple(K,nltk_train_data,train1,nltk_parser))\n",
    "    # creates a dict with featurereduction techniques, accuracy, and feature counts\n",
    "    dict_metrics_nb.update({featurereductions[i]: accuracies[i]})\n",
    "    print (accuracies[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "a bytes-like object is required, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-db4c6775deb6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdict_metrics_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturereductions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnltk_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_nltk_train_data\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeaturereductions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfeaturereductions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0maccuracies2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fold_validation_simple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnltk_train_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnltk_parser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-69-4eb1822ba684>\u001b[0m in \u001b[0;36mcreate_nltk_train_data\u001b[1;34m(feature_reduction)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sentences\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sentiment\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnltk_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateTrainingDataNLTK\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_label\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnltk_train_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-15fa2bf3a542>\u001b[0m in \u001b[0;36mcreateTrainingDataNLTK\u001b[1;34m(sentences, labels)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0md_tuple\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_tuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'"
     ]
    }
   ],
   "source": [
    "#LR \n",
    "K = 5; # Constant for K-fold cross validation\n",
    "accuracies2 = []\n",
    "dict_metrics_lr = {}\n",
    "for i in range(0, len(featurereductions)):\n",
    "    nltk_train_data = create_nltk_train_data (featurereductions[i])\n",
    "    print (featurereductions[i])\n",
    "    accuracies2.append(k_fold_validation_simple(K,nltk_train_data,train2,nltk_parser))\n",
    "    # creates a dict with featurereduction techniques, accuracy, and feature counts\n",
    "    dict_metrics_lr.update({featurereductions[i]: accuracies2[i]})\n",
    "    print (accuracies2[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
