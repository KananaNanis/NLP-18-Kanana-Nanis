{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##import libraries\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read file into pandas\n",
    "# 3 files are yelp_labelled.txt, amazon_cells_labelled.txt, imdb_labelled\n",
    "txt_file = 'amazon_cells_labelled.txt';\n",
    "data = pd.read_csv(txt_file, sep=\"\\t\", names=['reviews', 'sentiment'])\n",
    "X = data.reviews\n",
    "y = data.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##get the test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training on unnormalized data set\n",
    "def unNormalized_NBTrain():\n",
    "    # Vectorise the dataset\n",
    "    vect = CountVectorizer()\n",
    "    #Using training data to transform text into counts of features for each message\n",
    "    X_train_features = vect.fit_transform(X_train)\n",
    "    ## Train the naive Bayes classifier\n",
    "    NB = MultinomialNB()\n",
    "    classifier=NB.fit(X_train_features, y_train)\n",
    "    return classifier, vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unNormalized_NBAccuracy(filename, writeFile=\"NB-Unnormalized.txt\"):\n",
    "##    Test on a new document\n",
    "    classifier, vect  = unNormalized_NBTrain()\n",
    "    test_data = []\n",
    "    with open(filename, 'r') as rf:\n",
    "        for line in rf:\n",
    "            test_data.append(line.strip('\\r\\n'))\n",
    "##    Using training data to transform text into counts of features for each message        \n",
    "    X_test_features = vect.transform(test_data)\n",
    "##    sentence prediction\n",
    "    predicted = classifier.predict(X_test_features)\n",
    "    # writing results to a file\n",
    "    with open(writeFile, 'w') as wf:\n",
    "        for prediction in predicted:\n",
    "            wf.write(str(prediction) + '\\n')\n",
    "\n",
    "    # calculate accuracy\n",
    "    classifier, vect  = unNormalized_NBTrain()\n",
    "    X_test_features = vect.transform(X_test)\n",
    "    predicted = classifier.predict(X_test_features)\n",
    "    accuracy = np.mean(predicted == y_test)\n",
    "    print(\"Accuracy: Normalized NB: \" + str(round(accuracy, 3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training on normalized data set\n",
    "def normalized_NBTrain():\n",
    "    # Vectorise the dataset\n",
    "    #convert text into features\n",
    "    vect = CountVectorizer(stop_words = 'english', ngram_range = (1,1), max_df = .80, min_df = 4)\n",
    "    X_train_features = vect.fit_transform(X_train)\n",
    "\n",
    "    # Fit the estimator and transform the vector to tf-idf\n",
    "    tf_transformer  = TfidfTransformer()\n",
    "    X_train_tf  = tf_transformer.fit_transform(X_train_features)\n",
    "    \n",
    "    # Train the naive Bayes classifier\n",
    "    classifier = MultinomialNB().fit(X_train_tf ,y_train)\n",
    "\n",
    "    # return trained model\n",
    "    return classifier, vect, tf_transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_NBAccuracy(filename, writeFile=\"NB-Normalized.txt\"):\n",
    "    ##    Test on a file\n",
    "    classifier, vect, tf_transformer  = normalized_NBTrain()\n",
    "    test_data = []\n",
    "    with open(filename, 'r') as rf:\n",
    "        for line in rf:\n",
    "            test_data.append(line.strip('\\r\\n'))\n",
    "##    transform the vector\n",
    "    X_test_features = vect.transform(test_data) \n",
    "    X_test_tf = tf_transformer.transform(X_test_features)\n",
    "    predicted = classifier.predict(X_test_tf)\n",
    "\n",
    "    # write to file\n",
    "    with open(writeFile, 'w') as wf:\n",
    "        for prediction in predicted:\n",
    "            wf.write(str(prediction) + '\\n')\n",
    "            \n",
    "    # calculate accuracy\n",
    "    classifier, vect, tfidf_transformer  = normalized_NBTrain()\n",
    "    X_test_features = vect.transform(X_test)\n",
    "    predicted = classifier.predict(X_test_features)\n",
    "    accuracy = np.mean(predicted == y_test)\n",
    "    print(\"Accuracy: Un-Normalized NB: \" + str(round(accuracy, 3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-normalized Logistic Regression \n",
    "##Training an unnormalized logistic regression model\n",
    "def unNormalized_LRTrain():\n",
    "    ##initialize CountVectorizer\n",
    "    ##transform training dataset to word features\n",
    "    vect = CountVectorizer()\n",
    "    X_train_features = vect.fit_transform(X_train)\n",
    "    # train model with training dataset\n",
    "    LR = LogisticRegression(solver='lbfgs').fit(X_train_features, y_train)\n",
    "    return LR, vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Calculate LR (unnormalized data) accuracy \n",
    "def unNormalized_LRAccuracy(filename, writeFile=\"LR-Unnormalized.txt\"):\n",
    "    LR, vect  = unNormalized_LRTrain()\n",
    "    test_data = []\n",
    "    with open(filename, 'r') as rf:\n",
    "        for line in rf:\n",
    "            test_data.append(line.strip('\\r\\n'))\n",
    "    # transform test_data to features\n",
    "    X_test_features = vect.transform(test_data) \n",
    "    predicted = LR.predict(X_test_features)\n",
    "    \n",
    "    # write prediction to file\n",
    "    with open(writeFile, 'w') as wf:\n",
    "        for prediction in predicted:\n",
    "            wf.write(str(prediction) + '\\n')\n",
    "\n",
    "    LR, vect  = unNormalized_LRTrain()\n",
    "    # transform test_data to features\n",
    "    X_test_features = vect.transform(X_test)\n",
    "    predicted = LR.predict(X_test_features)\n",
    "    accuracy = np.mean(predicted == y_test)\n",
    "    print(\"Accuracy: Normalized LR: \" + str(round(accuracy, 3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Normalized Logistic Regression  \n",
    "def normalized_LRTrain():\n",
    "    #convert text into features\n",
    "    vect = CountVectorizer(stop_words='english',lowercase = True, ngram_range = (1,1), max_df = .80, min_df = 4)\n",
    "    # transform training dataset to word features \n",
    "    X_train_features =vect.fit_transform(X_train)\n",
    "    # solve frequency discrepancies among long and short sentences\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    X_train_tfidf = tfidf_transformer.fit_transform(X_train_features)\n",
    "    \n",
    "    LR = LogisticRegression(solver='lbfgs').fit(X_train_tfidf, y_train)\n",
    "    return LR, vect, tfidf_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_LRAccuracy(filename, writeFile=\"LR-Normalized.txt\"):\n",
    "    LR, vect, tf_transformer  = normalized_LRTrain()\n",
    "    # load data for testing\n",
    "    test_data = []\n",
    "    with open(filename, 'r') as rf:\n",
    "        for line in rf:\n",
    "            test_data.append(line.strip('\\r\\n'))\n",
    "\n",
    "    X_test_features = vect.transform(test_data) \n",
    "    X_test_tf = tf_transformer.transform(X_test_features)\n",
    "\n",
    "    # predict test sentences\n",
    "    predicted = LR.predict(X_test_tf)\n",
    "    # write to file\n",
    "    with open(writeFile, 'w') as wf:\n",
    "        for prediction in predicted:\n",
    "            wf.write(str(prediction) + '\\n')\n",
    "\n",
    "##    calculate accuracy of the normalized LR model\n",
    "    LR, vect, tf_transformer = normalized_LRTrain()\n",
    "    X_test_features = vect.transform(X_test)\n",
    "    predicted = LR.predict(X_test_features)\n",
    "    accuracy = np.mean(predicted == y_test)\n",
    "    # print accuracy\n",
    "    print(\"Accuracy: Un-Normalized LR: \" + str(round(accuracy, 3)))\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: Normalized NB: 0.78\n",
      "Accuracy: Un-Normalized NB: 0.66\n",
      "Accuracy: Normalized LR: 0.81\n",
      "Accuracy: Un-Normalized LR: 0.735\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    unNormalized_NBAccuracy('yelp_labelled.txt')\n",
    "    \n",
    "    normalized_NBAccuracy('yelp_labelled.txt')\n",
    "    \n",
    "    unNormalized_LRAccuracy('yelp_labelled.txt')\n",
    "\n",
    "    normalized_LRAccuracy('yelp_labelled.txt')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
